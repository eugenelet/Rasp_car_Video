/**
 * OpenCV video streaming over TCP/IP
 * Client: Receives video from server and display it
 * by Isaac Maia
 */

#define DATAGRAM_SIZE 8


/*************************************
        OP CODE
**************************************/

#define CONTROL 0x01
#define PICTURE 0x02
#define VIDEO   0x03

/*************************************
        FUNCTION
**************************************/


/**************************
        CONTROL
***************************/
#define IDLE    0x00
#define FORWARD 0x01
#define BACK    0x02
#define LEFT    0x03
#define RIGHT   0x04


/**************************
        VIDEO
***************************/
#define START   0x00
#define VALID   0x01
#define REQUEST 0x02
#define STOP    0x03
#define SENT    0x04


#include "opencv2/opencv.hpp"
#include <sys/socket.h> 
#include <arpa/inet.h>
#include <unistd.h>
#include <iostream>
#include <stdio.h>
#include <stdlib.h>
#include "getChar.cpp"
#include "transmit.h"
#include "receiver.h"
#include "kbhit.cpp"
#include <termios.h>

#include "opencv2/core/core.hpp"
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/calib3d/calib3d.hpp"
#include "opencv2/xfeatures2d/nonfree.hpp"
#include <opencv2/imgproc.hpp>
//#include <legacy/legacy.hpp>
#include <ctime>
#include <iomanip>

using namespace cv;
using namespace std;

int keyIn;
int sokt;

int localSocket;
int remoteSocket;
int serverPort;
int doneFlag = 1;
int counter = 0;
static char* snd_PORT="2023";
static char* rcv_PORT="2022";
//static char* IP_ADDR="127.0.0.1";
static char* IP_ADDR="192.168.2.100";


void printH(Mat H);
void* getch_thread(void* data){
    unsigned char output[DATAGRAM_SIZE];
	unsigned char* receivedPacket;
    int bytes;
	transmit_init(IP_ADDR, snd_PORT);   
	receiver_init(rcv_PORT); 
    while(1){
		tcflush(STDIN_FILENO, TCIFLUSH);	
		keyIn = getch();
        switch(keyIn){
            case 'a':{
                cout <<"left"<<endl;
                output[0] = CONTROL;
                output[1] = LEFT;
                transmit(output);
                break;
            }
            case 's':{
                cout <<"back"<<endl;
                output[0] = CONTROL;
                output[1] = BACK;
                transmit(output);
                break;
            }
            case 'd':{
                cout <<"right"<<endl;
                output[0] = CONTROL;
                output[1] = RIGHT;
                transmit(output);
                break;
            }
            case 'w':{
                cout <<"forward"<<endl;
                output[0] = CONTROL;
                output[1] = FORWARD;
                transmit(output);
                break;
            }
            case 'v':{
               //  //   transmit(output);
               // }
                break;
            }
            default:{
                cout <<"idle"<<endl;
                output[0] =  CONTROL;
                output[1] = IDLE;
                transmit(output);
                break;
            }
        
        }
		receivedPacket = receiver();
		cout << "ACK!" << endl;
    }
    pthread_exit(NULL);
}



int main(int argc, char** argv)
{

    pthread_t  getch_t, video_t;


    pthread_create(&getch_t, NULL, getch_thread, (void*)&keyIn);


    //----------------------------------------------------------
    //OpenCV Code
    //----------------------------------------------------------
    cv::VideoCapture vcap;
    cv::Mat image;

    const std::string videoStreamAddress = "http://192.168.2.100:8080/?action=stream"; 
    /* it may be an address of an mjpeg stream, 
    e.g. "http://user:pass@cam_address:8081/cgi/mjpg/mjpg.cgi?.mjpg" */

    //open the video stream and make sure it's opened
    if(!vcap.open(videoStreamAddress)) {
        std::cout << "Error opening video stream or file" << std::endl;
        return -1; 
    }  


    Mat img_object = imread("usb_cable.jpg", CV_LOAD_IMAGE_GRAYSCALE);
    Mat img_scene;
    int minHessian = 400;
    //SiftFeatureDetector detector(minHessian);
    Ptr<FeatureDetector> detector = ORB::create(minHessian);
    vector< KeyPoint > keypoints_object, keypoints_scene;

    detector->detect(img_object, keypoints_object);
    //VideoCapture cap(0); // open the default camera
    //if(!cap.isOpened())  // check if we succeeded
    //    return -1; 
    //step 2
    //SiftDescriptorExtractor extractor;
    Ptr<DescriptorExtractor> extractor = ORB::create();
    Mat descriptors_object, descriptors_scene;
    extractor->compute(img_object, keypoints_object, descriptors_object);

    while (1){
        //Mat img_webcam;
        //CvCapture *capture;
        //capture = cvCaptureFromCAM(0);
        //img_webcam = cvQueryFrame(capture);
        if(!vcap.read(img_scene)) {
            std::cout << "No frame" << std::endl;
            cv::waitKey();
        }
        //cap >> img_scene;
        //Mat img_scene(img_webcam, 0);
        
        //Mat img_scene = imread("EDA3.jpg", CV_LOAD_IMAGE_GRAYSCALE);

        //if (!img_object.data || !img_scene.data){
        //  cout << " --(!) Error reading images " << std::endl;
        //  return -1;
        //}
        //-- Step 1: Detect the keypoints using SURF Detector
        //threshold for hessian keypoint detector used in SURF
        

        clock_t start, end;

        //detect keypoints
        start = clock();
        detector->detect(img_scene, keypoints_scene);
        end = clock();
        //cout << "Detect keypoints use " << (double)(end - start) / CLOCKS_PER_SEC << " secs" << endl;
        //-- Step 2: Calculate descriptors(feature vectors)
        
        //(¹Ï, ¯S¼xÂI, ¯S¼x¦V¶q)
        start = clock();
        extractor->compute(img_scene, keypoints_scene, descriptors_scene);
        end = clock();
        //cout << "Compute descriptors use " << (double)(end - start) / CLOCKS_PER_SEC << " secs" << endl;


        //-- Step 3: Matching descriptor vectors using FLANN matcher
        FlannBasedMatcher matcher;
        vector< DMatch > matches;
        if(descriptors_object.type()!=CV_32F) {
            descriptors_object.convertTo(descriptors_object, CV_32F);
        }
        
        if(descriptors_scene.type()!=CV_32F) {
            descriptors_scene.convertTo(descriptors_scene, CV_32F);
        }
        start = clock();
        matcher.match(descriptors_object, descriptors_scene, matches);
        end = clock();
        //cout << "Match use " << (double)(end - start) / CLOCKS_PER_SEC << " secs" << endl;

        double max_dist = 0; double min_dist = 100;

        //-- Quick calculation of max and min distances between keypoints
        //cout << "\n\n" << descriptors_object.rows << "\n\n";
        for (int i = 0; i < descriptors_object.rows; ++i){
            double dist = matches[i].distance;
            if (dist < min_dist)
                min_dist = dist;
            if (dist > max_dist)
                max_dist = dist;
        }

        //cout << "Max dist : " << max_dist << "\n";
        //cout << "Min dist : " << min_dist << "\n";

        //-- Draw only "good" matches (i.e. whose distance is less than 3*min_dist )
        vector< DMatch > good_matches;

        for (int i = 0; i < descriptors_object.rows; ++i){

            if (matches[i].distance < 3 * min_dist)
                good_matches.push_back(matches[i]);
        }

        Mat img_matches;
        start = clock();
        drawMatches(img_object, keypoints_object, img_scene, keypoints_scene,
            good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),
            vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
        end = clock();
        //cout << "Draw matches use " << (double)(end - start) / CLOCKS_PER_SEC << " secs" << endl;
        //-- Localize the object
        start = clock();
        vector< Point2f > obj;
        vector< Point2f > scene;

        for (int i = 0; i < good_matches.size(); ++i){
            //-- Get the keypoints from the good matches
            obj.push_back(keypoints_object[good_matches[i].queryIdx].pt);
            scene.push_back(keypoints_scene[good_matches[i].trainIdx].pt);
        }
        Mat H;
        if(obj.size() && scene.size()){
            H = findHomography(obj, scene, CV_RANSAC);
        }
        
        //-- Get the corners from the image_1 ( the object to be "detected" )
        if(!H.empty()){
            //printH(H);
    
            vector< Point2f > obj_corners(4);
            obj_corners[0] = cvPoint(0, 0);
            obj_corners[1] = cvPoint(img_object.cols, 0);
            obj_corners[2] = cvPoint(img_object.cols, img_object.rows);
            obj_corners[3] = cvPoint(0, img_object.rows);
            vector< Point2f > scene_corners(4);
    
            perspectiveTransform(obj_corners, scene_corners, H);
    
            //-- Draw lines between the corners (the mapped object in the scene - image_2 )
            line(img_matches, scene_corners[0] + Point2f(img_object.cols, 0), scene_corners[1] + Point2f(img_object.cols, 0), Scalar(0, 255, 0), 4);
            line(img_matches, scene_corners[1] + Point2f(img_object.cols, 0), scene_corners[2] + Point2f(img_object.cols, 0), Scalar(0, 255, 0), 4);
            line(img_matches, scene_corners[2] + Point2f(img_object.cols, 0), scene_corners[3] + Point2f(img_object.cols, 0), Scalar(0, 255, 0), 4);
            line(img_matches, scene_corners[3] + Point2f(img_object.cols, 0), scene_corners[0] + Point2f(img_object.cols, 0), Scalar(0, 255, 0), 4);
            end = clock();
            //cout << "Localize the object use " << (double)(end - start) / CLOCKS_PER_SEC << " secs" << endl;
            //-- Show detected matches
            imshow("Good Matches & Object detection", img_matches);
    
            cout << "\n";
            waitKey(1);
        }
        
    } 

    //Create output window for displaying frames. 
    //It's important to create this window outside of the `for` loop
    //Otherwise this window will be created automatically each time you call
    //`imshow(...)`, which is very inefficient. 
//    cv::namedWindow("Output Window");

//    for(;;) {
//        if(!vcap.read(image)) {
//            std::cout << "No frame" << std::endl;
//            cv::waitKey();
//        }   
//        cv::imshow("Output Window", image);
////        if(cv::waitKey(500) >= 0) break;                                                                                                     }   
//		cv::waitKey(1);
//	}
    return 0;
}

void printH(Mat H)
{
    for (int i = 0; i < 3; ++i){
        for (int j = 0; j < 3; ++j){
            cout << ::left << ::setw(15) << ::setfill(' ') << H.at< double >(i, j);
            //cout << H.at< double >(i, j);
            //cout << "\t\t";
        }
        cout << "\n";
    }
}
	
